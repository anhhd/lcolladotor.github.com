<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rstats on L. Collado-Torres</title>
    <link>http://lcolladotor.github.io/tags/rstats/index.xml</link>
    <description>Recent content in Rstats on L. Collado-Torres</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2011-2017 Leonardo Collado Torres under (CC) BY-NC-SA</copyright>
    <atom:link href="/tags/rstats/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>userR2013 data analysis contest: data exploration</title>
      <link>http://lcolladotor.github.io/2013/06/12/userr2013-data-analysis-contest-data-exploration</link>
      <pubDate>Wed, 12 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2013/06/12/userr2013-data-analysis-contest-data-exploration</guid>
      <description>&lt;h1&gt;Description&lt;/h1&gt;
&lt;p&gt;The useR2013 conference is organizing a data analysis contest, check the &lt;a href=&#34;http://www.edii.uclm.es/%7EuseR-2013/docs/announce.pdf&#34;&gt;rules here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;They have a package called &lt;strong&gt;useR2013DAC&lt;/strong&gt; with two data sets: one from La Liga and the other one from the Formula 1. Once you download and install the package (&lt;a href=&#34;http://www.edii.uclm.es/%7EuseR-2013/#contest&#34;&gt;available here&lt;/a&gt;), you can quickly explore the data using the following R commands:&lt;/p&gt;
&lt;h1&gt;Data exploration&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Load the package
library(useR2013DAC)

## Explore laliga data
data(laliga)
head(laliga)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;##    Season Week               HomeTeam                    AwayTeam
## 1 2008/09    1   Athletic Club Bilbao     Union Deportiva Almeria
## 2 2008/09    1        Atlético Madrid                   Málaga CF
## 3 2008/09    1          Betis Sevilla Real Club Recreativo Huelva
## 4 2008/09    1             CA Osasuna               Villarreal CF
## 5 2008/09    1            CD Numancia                FC Barcelona
## 6 2008/09    1 Deportivo de La Coruña              Real Madrid CF
##   HomeGoals AwayGoals
## 1         1         3
## 2         4         0
## 3         0         1
## 4         1         1
## 5         1         0
## 6         2         1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(laliga)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;##     Season               Week        HomeTeam           AwayTeam        
##  Length:1900        Min.   : 1.0   Length:1900        Length:1900       
##  Class :character   1st Qu.:10.0   Class :character   Class :character  
##  Mode  :character   Median :19.5   Mode  :character   Mode  :character  
##                     Mean   :19.5                                        
##                     3rd Qu.:29.0                                        
##                     Max.   :38.0                                        
##                                                                         
##    HomeGoals      AwayGoals   
##  Min.   :0.00   Min.   :0.00  
##  1st Qu.:1.00   1st Qu.:0.00  
##  Median :1.00   Median :1.00  
##  Mean   :1.65   Mean   :1.14  
##  3rd Qu.:2.00   3rd Qu.:2.00  
##  Max.   :8.00   Max.   :8.00  
##  NA&#39;s   :50     NA&#39;s   :50
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lapply(laliga, class)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## $Season
## [1] &amp;quot;character&amp;quot;
## 
## $Week
## [1] &amp;quot;integer&amp;quot;
## 
## $HomeTeam
## [1] &amp;quot;character&amp;quot;
## 
## $AwayTeam
## [1] &amp;quot;character&amp;quot;
## 
## $HomeGoals
## [1] &amp;quot;integer&amp;quot;
## 
## $AwayGoals
## [1] &amp;quot;integer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Explore formula1 data
data(formula1)
head(formula1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;##   Pos No             Driver             Team Laps        Time Grid Pts
## 1   1  8    Fernando Alonso          Ferrari   49 1:39:20.396    3  25
## 2   2  7       Felipe Massa          Ferrari   49  +16.0 secs    2  18
## 3   3  2     Lewis Hamilton McLaren-Mercedes   49  +23.1 secs    4  15
## 4   4  5   Sebastian Vettel      RBR-Renault   49  +38.7 secs    1  12
## 5   5  4       Nico Rosberg      Mercedes GP   49  +40.2 secs    5  10
## 6   6  3 Michael Schumacher      Mercedes GP   49  +44.1 secs    7   8
##                                         Race Season
## 1 2010 FORMULA 1 GULF AIR BAHRAIN GRAND PRIX   2010
## 2 2010 FORMULA 1 GULF AIR BAHRAIN GRAND PRIX   2010
## 3 2010 FORMULA 1 GULF AIR BAHRAIN GRAND PRIX   2010
## 4 2010 FORMULA 1 GULF AIR BAHRAIN GRAND PRIX   2010
## 5 2010 FORMULA 1 GULF AIR BAHRAIN GRAND PRIX   2010
## 6 2010 FORMULA 1 GULF AIR BAHRAIN GRAND PRIX   2010
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(formula1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;##       Pos            No                     Driver    
##  Ret    :254   1      :  58   Felipe Massa     :  58  
##  1      : 58   10     :  58   Fernando Alonso  :  58  
##  10     : 58   11     :  58   Heikki Kovalainen:  58  
##  11     : 58   12     :  58   Jenson Button    :  58  
##  12     : 58   14     :  58   Kamui Kobayashi  :  58  
##  13     : 58   15     :  58   Lewis Hamilton   :  58  
##  (Other):848   (Other):1044   (Other)          :1044  
##                    Team          Laps             Time          Grid     
##  Ferrari             :116   55     :125   +1 Lap    :268   1      :  58  
##  Force India-Mercedes:116   56     :121   +2 Laps   :102   10     :  58  
##  HRT-Cosworth        :116   53     : 92   Accident  : 93   11     :  58  
##  McLaren-Mercedes    :116   57     : 80   +3 Laps   : 41   12     :  58  
##  STR-Ferrari         :116   70     : 75   Hydraulics: 26   13     :  58  
##  Lotus-Renault       : 78   52     : 69   Gearbox   : 24   14     :  58  
##  (Other)             :734   (Other):830   (Other)   :838   (Other):1044  
##       Pts          Race               Season    
##         :812   Length:1392        Min.   :2010  
##  1      : 58   Class :character   1st Qu.:2010  
##  10     : 58   Mode  :character   Median :2011  
##  12     : 58                      Mean   :2011  
##  15     : 58                      3rd Qu.:2012  
##  18     : 58                      Max.   :2012  
##  (Other):290
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lapply(formula1, class)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## $Pos
## [1] &amp;quot;factor&amp;quot;
## 
## $No
## [1] &amp;quot;factor&amp;quot;
## 
## $Driver
## [1] &amp;quot;factor&amp;quot;
## 
## $Team
## [1] &amp;quot;factor&amp;quot;
## 
## $Laps
## [1] &amp;quot;factor&amp;quot;
## 
## $Time
## [1] &amp;quot;factor&amp;quot;
## 
## $Grid
## [1] &amp;quot;factor&amp;quot;
## 
## $Pts
## [1] &amp;quot;factor&amp;quot;
## 
## $Race
## [1] &amp;quot;character&amp;quot;
## 
## $Season
## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;p&gt;I don&amp;#8217;t see a specific question that they want you to answer with this data, but if you find one related to data analysis or visualization then join the competition!&lt;/p&gt;
&lt;p&gt;Note that you must be attending the conference in order to be eligible to compete.&lt;/p&gt;
&lt;h1&gt;Reproducibility&lt;/h1&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sessionInfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## R version 3.0.0 (2013-04-03)
## Platform: x86_64-apple-darwin10.8.0 (64-bit)
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] useR2013DAC_0.1-1 knitr_1.2        
## 
## loaded via a namespace (and not attached):
## [1] digest_0.6.3   evaluate_0.4.3 formatR_0.7    stringr_0.6.2 
## [5] tools_3.0.0
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Using plyr and doMC for quick and easy apply-family functions</title>
      <link>http://lcolladotor.github.io/2013/04/26/using-plyr-and-domc-for-quick-and-easy-apply-family</link>
      <pubDate>Fri, 26 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2013/04/26/using-plyr-and-domc-for-quick-and-easy-apply-family</guid>
      <description>&lt;p&gt;A few weeks back I dedicated a short amount of time to actually read what &lt;code&gt;plyr&lt;/code&gt; (&lt;span class=&#34;showtooltip&#34; title=&#34;Wickham H (2011). The Split-Apply-Combine Strategy for Data
Analysis. _Journal of Statistical Software_, *40*(1), pp. 1-29.
 http://www.jstatsoft.org/v40/i01/.&#34;&gt;&lt;a href=&#34;http://www.jstatsoft.org/v40/i01/&#34;&gt;Wickham, 2011&lt;/a&gt;&lt;/span&gt;) is about and I was surprised. The whole idea behind &lt;code&gt;plyr&lt;/code&gt; is very simple: expand the &lt;code&gt;apply()&lt;/code&gt; family to do things easy. &lt;code&gt;plyr&lt;/code&gt; has many functions whose name ends with &lt;code&gt;ply&lt;/code&gt; which is short of apply. Then, the functions are identified by two letters before &lt;code&gt;ply&lt;/code&gt; which are abbreviations for the input (first letter) and output (second one). For instance, &lt;code&gt;ddply&lt;/code&gt; takes an input a &lt;code&gt;data.frame&lt;/code&gt; and returns a &lt;code&gt;data.frame&lt;/code&gt; while &lt;code&gt;ldply&lt;/code&gt; takes as input a &lt;code&gt;list&lt;/code&gt; and returns a &lt;code&gt;data.frame&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The syntax is pretty straight forward. For example, here are the arguments for &lt;code&gt;ddply&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(plyr)
args(ddply)
## function (.data, .variables, .fun = NULL, ..., .progress = &amp;quot;none&amp;quot;, 
##     .inform = FALSE, .drop = TRUE, .parallel = FALSE, .paropts = NULL) 
## NULL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What we basically have to specify are&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;.data&lt;/code&gt; which in general is the name of the input &lt;code&gt;data.frame&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.variables&lt;/code&gt; which is a vector (note the use of the &lt;code&gt;.&lt;/code&gt; function) of variable names. In this case, &lt;code&gt;ddply&lt;/code&gt; is very useful for applying some function to subsets of the data as specified by these variables,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.fun&lt;/code&gt; which is the actual function we want to run,&lt;/li&gt;
&lt;li&gt;and &lt;code&gt;...&lt;/code&gt; which are parameter options for the function we are running.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;From the &lt;code&gt;ddply&lt;/code&gt; help page we have the following examples:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dfx &amp;lt;- data.frame(
  group = c(rep(&#39;A&#39;, 8), rep(&#39;B&#39;, 15), rep(&#39;C&#39;, 6)),
  sex = sample(c(&amp;quot;M&amp;quot;, &amp;quot;F&amp;quot;), size = 29, replace = TRUE),
  age = runif(n = 29, min = 18, max = 54)
)

# Note the use of the &#39;.&#39; function to allow
# group and sex to be used without quoting
ddply(dfx, .(group, sex), summarize,
 mean = round(mean(age), 2),
 sd = round(sd(age), 2))
##   group sex  mean    sd
## 1     A   F 40.48 12.72
## 2     A   M 34.48 15.28
## 3     B   F 36.05  9.98
## 4     B   M 38.35  7.97
## 5     C   F 20.04  1.86
## 6     C   M 43.81 10.72

# An example using a formula for .variables
ddply(baseball[1:100, ], ~year, nrow)

##   year V1
## 1 1871  7
## 2 1872 13
## 3 1873 13
## 4 1874 15
## 5 1875 17
## 6 1876 15
## 7 1877 17
## 8 1878  3

# Applying two functions; nrow and ncol
ddply(baseball, .(lg), c(&amp;quot;nrow&amp;quot;, &amp;quot;ncol&amp;quot;))

##   lg  nrow ncol
## 1       65   22
## 2 AA   171   22
## 3 AL 10007   22
## 4 FL    37   22
## 5 NL 11378   22
## 6 PL    32   22
## 7 UA     9   22
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But this is not the end of the story! Something I really liked about &lt;code&gt;plyr&lt;/code&gt; is that it can be parallelized via the &lt;code&gt;foreach&lt;/code&gt; (&lt;span class=&#34;showtooltip&#34; title=&#34;Analytics R (2012). _foreach: Foreach looping construct for R_. R
package version 1.4.0, 
http://CRAN.R-project.org/package=foreach.&#34;&gt;&lt;a href=&#34;http://CRAN.R-project.org/package=foreach&#34;&gt;Analytics, 2012&lt;/a&gt;&lt;/span&gt;) package. I don&amp;#8217;t know much about &lt;code&gt;foreach&lt;/code&gt;, but all I learnt is that you have to use other packages such as &lt;code&gt;doMC&lt;/code&gt; (&lt;span class=&#34;showtooltip&#34; title=&#34;Analytics R (2013). _doMC: Foreach parallel adaptor for the
multicore package_. R package version 1.3.0, 
http://CRAN.R-project.org/package=doMC.&#34;&gt;&lt;a href=&#34;http://CRAN.R-project.org/package=doMC&#34;&gt;Analytics, 2013&lt;/a&gt;&lt;/span&gt;) to actually run the code. It&amp;#8217;s like &lt;code&gt;foreach&lt;/code&gt; specifies the infraestructure to communicate in parallel (and split jobs) and packages like &lt;code&gt;doMC&lt;/code&gt; tailor it for specific environments like for running in multi-core.&lt;/p&gt;
&lt;p&gt;Running things in parallel can then be very easy. Basically, you load the packages, specify the number of cores, and run your &lt;code&gt;ply&lt;/code&gt; function. Here is a short example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Load packages
library(plyr)
library(doMC)

## Loading required package: foreach
## Loading required package: iterators
## Loading required package: parallel

## Specify the number of cores
registerDoMC(4)

## Check how many cores we are using
getDoParWorkers()
## [1] 4

## Run your ply function
ddply(dfx, .(group, sex), summarize, mean = round(mean(age), 2), sd = round(sd(age), 
    2), .parallel = TRUE)

##   group sex  mean    sd
## 1     A   F 40.48 12.72
## 2     A   M 34.48 15.28
## 3     B   F 36.05  9.98
## 4     B   M 38.35  7.97
## 5     C   F 20.04  1.86
## 6     C   M 43.81 10.72
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In case that you are interested, here is a short shell script for knitting an Rmd file in the cluster and specifying the appropriate number of cores to then use &lt;code&gt;plyr&lt;/code&gt; and &lt;code&gt;doMC&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash 
# To run it in the current working directory
#$ -cwd 
# To get an email after the job is done
#$ -m e 
# To speficy that we want 4 cores
#$ -pe local 4
# The name of the job
#$ -N myPlyJob

echo &amp;quot;**** Job starts ****&amp;quot;
date

# Knit your file: assuming it&#39;s called FileToKnit.Rmd
Rscript -e &amp;quot;library(knitr); knit2html(&#39;FileToKnit.Rmd&#39;)&amp;quot;

echo &amp;quot;**** Job ends ****&amp;quot;
date
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lets say that the bash script is named &lt;code&gt;script.sh&lt;/code&gt;. Then you can submit it to the cluster queue using&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;
qsub script.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;p&gt;This is what I used to re-format a large &lt;code&gt;data.frame&lt;/code&gt; in a few minutes in the cluster for the &lt;a href=&#34;https://twitter.com/search?q=%23jhsph753&amp;amp;src=typd&#34;&gt;#jhsph753&lt;/a&gt; class homework project.&lt;/p&gt;
&lt;p&gt;So, thank you again &lt;a href=&#34;https://twitter.com/hadleywickham&#34;&gt;Hadley Wickham&lt;/a&gt; for making awesome R packages!&lt;/p&gt;
&lt;p&gt;Citations made with &lt;code&gt;knitcitations&lt;/code&gt; (&lt;span class=&#34;showtooltip&#34; title=&#34;Boettiger C (2013). _knitcitations: Citations for knitr markdown
files_. R package version 0.4-4, 
https://github.com/cboettig/knitcitations.&#34;&gt;&lt;a href=&#34;https://github.com/cboettig/knitcitations&#34;&gt;Boettiger, 2013&lt;/a&gt;&lt;/span&gt;).&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Revolution Analytics, (2013) doMC: Foreach parallel adaptor for the multicore package. &lt;a href=&#34;http://CRAN.R-project.org/package=doMC&#34;&gt;&lt;a href=&#34;http://CRAN.R-project.org/package=doMC&#34;&gt;http://CRAN.R-project.org/package=doMC&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Revolution Analytics, (2012) foreach: Foreach looping construct for R. &lt;a href=&#34;http://CRAN.R-project.org/package=foreach&#34;&gt;&lt;a href=&#34;http://CRAN.R-project.org/package=foreach&#34;&gt;http://CRAN.R-project.org/package=foreach&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Carl Boettiger, knitcitations: Citations for knitr markdown files. &lt;a href=&#34;https://github.com/cboettig/knitcitations&#34;&gt;&lt;a href=&#34;https://github.com/cboettig/knitcitations&#34;&gt;https://github.com/cboettig/knitcitations&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hadley Wickham, (2011) The Split-Apply-Combine Strategy for Data Analysis. &lt;em&gt;Journal of Statistical Software&lt;/em&gt; &lt;strong&gt;40&lt;/strong&gt; (1) &lt;a href=&#34;http://www.jstatsoft.org/v40/i01/&#34;&gt;&lt;a href=&#34;http://www.jstatsoft.org/v40/i01/&#34;&gt;http://www.jstatsoft.org/v40/i01/&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predicting who will win a NFL match at half time</title>
      <link>http://lcolladotor.github.io/2013/03/23/predicting-who-will-win-a-nfl-match-at-half-time</link>
      <pubDate>Sat, 23 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2013/03/23/predicting-who-will-win-a-nfl-match-at-half-time</guid>
      <description>&lt;p&gt;It was great to have a little break, &lt;em&gt;Spring break&lt;/em&gt;, although the weather didn&amp;#8217;t feel like spring at all! During the early part of the break I worked on my final project for Jeff Leek&amp;#8217;s data analysis class, which we call 140.753 here. Continuing &lt;a href=&#34;http://fellgernon.tumblr.com/tagged/jhsph753#.UU44Y1vF2c4&#34;&gt;my previous posts on the topic&lt;/a&gt;, this time I&amp;#8217;ll share the results of my final project.&lt;/p&gt;
&lt;p&gt;At the beginning of the course, we had to submit a project plan (more like a proposal) and &lt;a href=&#34;https://github.com/lcolladotor/lcollado753/blob/master/hw/projectplan/lcollado_projectplan.pdf&#34;&gt;in mine&lt;/a&gt; I announced my interest to look into some sports data. At the time I included a few links to Brian Burke&amp;#8217;s Advanced NFL Stats site (&lt;span class=&#34;showtooltip&#34; title=&#34;(2013). Advanced NFL Stats.   http://www.advancednflstats.com/ [Online. last-accessed:  2013-03-23 23:28:38].  http://www.advancednflstats.com/.&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/&#34;&gt;Burke&lt;/a&gt;&lt;/span&gt;). At the time I didn&amp;#8217;t know that Burke&amp;#8217;s site described in detail a lot of the information I would end up using.&lt;/p&gt;
&lt;p&gt;My final project had to do with splitting NFL games by half and then use only the play-by-play data from the first half to predict if team A or B would win the game. My overall goal was to have some fun with sports data which I had never looked at, but then also try to come up with something I would personally use in the future. So, why split games by half? I personally would like to know if I should keep watching a game or not at half time. Having a tool to help me decide would be great, and well, if the team I&amp;#8217;m rooting for has high chances of losing or winning, ideally I would switch to doing something else. A related question that I didn&amp;#8217;t try to answer is which half is worth watching? This would be a meaningful question if you only have time to watch one of them.&lt;/p&gt;
&lt;p&gt;To truly satisfy my goals, it wasn&amp;#8217;t enough to just build a predictive model. That is why I also built a web application using the &lt;code&gt;shiny&lt;/code&gt; package (&lt;span class=&#34;showtooltip&#34; title=&#34;RStudio and Inc. (2013). _shiny: Web Application Framework for R_.  R package version 0.4.0,   http://CRAN.R-project.org/package=shiny.&#34;&gt;&lt;a href=&#34;http://CRAN.R-project.org/package=shiny&#34;&gt;RStudio and Inc., 2013&lt;/a&gt;&lt;/span&gt;). It was the first time I did a shiny app, but thanks to the good manual and some examples on GitHub from John Muschelli like his &lt;a href=&#34;https://github.com/muschellij2/Shiny_model&#34;&gt;Shiny_model&lt;/a&gt; it wasn&amp;#8217;t so bad. I thus invite you to test and browse my shiny app at &lt;a href=&#34;http://glimmer.rstudio.com/lcolladotor/NFLhalf/&#34;&gt;&lt;a href=&#34;http://glimmer.rstudio.com/lcolladotor/NFLhalf/&#34;&gt;http://glimmer.rstudio.com/lcolladotor/NFLhalf/&lt;/a&gt;&lt;/a&gt;. It could be improved by adding some functions that scrape live data for the 2013 season so you don&amp;#8217;t have to input all the variables needed by using the sliders. Anyhow, I&amp;#8217;m happy with the result.&lt;/p&gt;
&lt;p&gt;The entire project&amp;#8217;s code, EDA steps, shiny app, and report are available via GitHub in my repository (&lt;span class=&#34;showtooltip&#34; title=&#34;lcolladotor (2013). lcollado753.   https://github.com/lcolladotor/lcollado753 [Online.  last-accessed: 2013-03-21 02:23:49].   https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half.&#34;&gt;&lt;a href=&#34;https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half&#34;&gt;lcollado753&lt;/a&gt;&lt;/span&gt;). While the details are in the report, I&amp;#8217;ll give a brief summary here.&lt;/p&gt;
&lt;p&gt;Basically, I summarized the play-by-play data for all NFL games from 2002 to 2012 seasons as provided by Burke (&lt;span class=&#34;showtooltip&#34; title=&#34;(2010). Advanced NFL Stats: Play-by-Play Data.   http://www.advancednflstats.com/2010/04/play-by-play-data.html  [Online. last-accessed: 2013-03-24 00:08:20].   http://www.advancednflstats.com/2010/04/play-by-play-data.html.&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2010/04/play-by-play-data.html&#34;&gt;Burke, 2010&lt;/a&gt;&lt;/span&gt;). I used some of the variables Burke uses (&lt;span class=&#34;showtooltip&#34; title=&#34;(2009). Advanced NFL Stats: How the Model Works-A Detailed  Example Part 1.   http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html  [Online. last-accessed: 2013-03-24 00:08:21].   http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html.&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html&#34;&gt;Burke, 2009&lt;/a&gt;&lt;/span&gt;) and some others like the score difference, who starts the second half, and the game day winning percentages of both teams. After exploring the data, I discarded the years 2002 to 2005. Then, I trained a model using the 2006 to 2011 data and did some quick model selection. Note that I&amp;#8217;m not doing the adjustment by opponent the way Burke did it (&lt;span class=&#34;showtooltip&#34; title=&#34;(2009). Advanced NFL Stats: How the Model Works-A Detailed  Example Part 2.   http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html  [Online. last-accessed: 2013-03-24 00:08:23].   http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html.&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html&#34;&gt;Burke, 2009-2&lt;/a&gt;&lt;/span&gt;) in part because I was running out of time, but also because the model already uses the current game winning percentages of both teams to consider the two team&amp;#8217;s strength. I evaluated the model using the 2012 data and after seeing that it worked decently enough, I trained a second model using the data from 2006 to 2012 so it can be used for the 2013 season. These two trained models are the ones available in the shiny app I made.&lt;/p&gt;
&lt;p&gt;In the report, I didn&amp;#8217;t include ROCs—a big miss—so here they go. The code I will show below is heavily based on a post on GLMs (&lt;span class=&#34;showtooltip&#34; title=&#34;denishaine (2013). Veterinary Epidemiologic Research: GLM  \ Evaluating Logistic Regression Models (part 3).   http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/  [Online. last-accessed: 2013-03-23 22:51:49].   http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/.&#34;&gt;&lt;a href=&#34;http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/&#34;&gt;denishaine, 2013&lt;/a&gt;&lt;/span&gt;). The code below is written in a way that you can easily reproduce it if you have cloned my repository for the 140.753 class (&lt;span class=&#34;showtooltip&#34; title=&#34;lcolladotor (2013). lcollado753.   https://github.com/lcolladotor/lcollado753 [Online.  last-accessed: 2013-03-21 02:23:49].   https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half.&#34;&gt;&lt;a href=&#34;https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half&#34;&gt;lcollado753&lt;/a&gt;&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;First, some setup steps.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Specify the directory where you cloned the lcollado753 repo
maindir &amp;lt;- &amp;quot;whereYouClonedTheRepo&amp;quot;
## Load packages needed
suppressMessages(library(ROCR))
library(ggplot2)

## Load fits.
## Remember that 1st one used data from 2006 to 2011
## and the 2nd one used data from 2006 to 2012.
load(paste0(maindir, &amp;quot;/lcollado753/final/nfl_half/EDA/model/fits.Rdata&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, I make the ROCs for both trained models using the data that they were trained on. They should be quite good since it uses the same data to build the model that it will then try to predict.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Make the ROC plots

## Simple list where I&#39;ll store all the results so I can compare the ROC plots later on
all &amp;lt;- list()

## Construct prediction function
for(i in 1:2) {
	## Predict on the original data
	pred &amp;lt;- predict(fits[[i]])
	
	## Subset original data (remove NA&#39;s)
	data &amp;lt;- fits[[i]]$data
	data &amp;lt;- data[complete.cases(data),]
	
	## Construct prediction function
	pred.fn &amp;lt;- prediction(pred, data$win)
	
	## Get performance info
	perform &amp;lt;- performance(pred.fn, &amp;quot;tpr&amp;quot;, &amp;quot;fpr&amp;quot;)
	
	## Get ready to plot
	toPlot &amp;lt;- data.frame(tpr = unlist(slot(perform, &amp;quot;y.values&amp;quot;)), fpr = unlist(slot(perform, &amp;quot;x.values&amp;quot;)))
	all &amp;lt;- c(all, list(toPlot))

	## Make the plot
	res &amp;lt;- ggplot(toPlot) + geom_line(aes(x=fpr, y=tpr)) + geom_abline(intercept=0, slope=1, colour=&amp;quot;orange&amp;quot;) + ylab(&amp;quot;Sensitivity&amp;quot;) + xlab(&amp;quot;1 - Specificity&amp;quot;) + ggtitle(paste(&amp;quot;Years 2006 to&amp;quot;, c(&amp;quot;2011&amp;quot;, &amp;quot;2012&amp;quot;)[i]))
	print(res)
	
	## Print the AUC value
	print(unlist(performance(pred.fn, &amp;quot;auc&amp;quot;)@y.values))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img alt=&#34;plot of chunk ROC&#34; src=&#34;http://i.imgur.com/b1FS2ml.png&#34;/&gt;&lt;/p&gt;
```r
## [1] 0.8506
```
&lt;p&gt;&lt;img alt=&#34;plot of chunk ROC&#34; src=&#34;http://i.imgur.com/f2UOySy.png&#34;/&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## [1] 0.8513
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Both ROC plots look pretty similar (well, the data sets are very similar!) and have relatively high AUC values.&lt;/p&gt;
&lt;p&gt;Next, I make the ROC plot using the model trained with the data from 2006 to 2011 to predict the outcomes for the 2012 games.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Load 2012 data
load(paste0(maindir, &amp;quot;/lcollado753/final/nfl_half/data/pred/info2012.Rdata&amp;quot;))

## Predict using model fit with data from 2006 to 2011
pred &amp;lt;- predict(fits[[1]], info2012)

## Construction prediction function
pred.fn &amp;lt;- prediction(pred, info2012$win)

## Get performance info
perform &amp;lt;- performance(pred.fn, &amp;quot;tpr&amp;quot;, &amp;quot;fpr&amp;quot;)

## Get ready to plot
toPlot &amp;lt;- data.frame(tpr = unlist(slot(perform, &amp;quot;y.values&amp;quot;)), fpr = unlist(slot(perform, &amp;quot;x.values&amp;quot;)))
all &amp;lt;- c(all, list(toPlot))

## Make the plot
ggplot(toPlot) + geom_line(aes(x=fpr, y=tpr)) + geom_abline(intercept=0, slope=1, colour=&amp;quot;orange&amp;quot;) + ylab(&amp;quot;Sensitivity&amp;quot;) + xlab(&amp;quot;1 - Specificity&amp;quot;) + ggtitle(&amp;quot;Model trained 2006-2011 predicting 2012&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img alt=&#34;plot of chunk pred2012&#34; src=&#34;http://i.imgur.com/DDcsW7W.png&#34;/&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Print the AUC value
print(unlist(performance(pred.fn, &amp;quot;auc&amp;quot;)@y.values))
## [1] 0.816
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The steps in the curve are more visible since it is using less data. It also seems to be a little less good than the other two, as expected. This is clear when comparing the AUC values.&lt;/p&gt;
&lt;p&gt;Finally, I plot all curves in the same picture to visually compare them.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;names(all) &amp;lt;- c(&amp;quot;train2011&amp;quot;, &amp;quot;train2012&amp;quot;, &amp;quot;pred2012&amp;quot;)
for(i in 1:3) {
	all[[i]] &amp;lt;- cbind(all[[i]], rep(names(all)[i], nrow(all[[i]])))
	colnames(all[[i]])[3] &amp;lt;- &amp;quot;set&amp;quot;
}
all &amp;lt;- do.call(rbind, all)

ggplot(all) + geom_line(aes(x=fpr, y=tpr, colour=set)) + geom_abline(intercept=0, slope=1, colour=&amp;quot;orange&amp;quot;) + ylab(&amp;quot;Sensitivity&amp;quot;) + xlab(&amp;quot;1 - Specificity&amp;quot;) + ggtitle(&amp;quot;Comparing ROCs&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;p&gt;&lt;img alt=&#34;plot of chunk allInOne&#34; src=&#34;http://i.imgur.com/tUVfgfs.png&#34;/&gt;&lt;/p&gt;
&lt;p&gt;Both ROCs with the trained data (train2011, train2012) are nearly identical and both are slightly superior to the one predicting the 2012 games.&lt;/p&gt;
&lt;p&gt;Overall I am happy with the results and while some things can certainly be improved, I look forward to the NFL 2013 season. Also, remember that Burke publishes his winning estimated probabilities from week 4 onward (&lt;span class=&#34;showtooltip&#34; title=&#34;BURKE BB (2013). Brian Burke - The Fifth Down Blog -  NYTimes.com.   http://fifthdown.blogs.nytimes.com/author/brian-burke/ [Online.  last-accessed: 2013-03-24 00:26:32].   http://fifthdown.blogs.nytimes.com/author/brian-burke/.&#34;&gt;&lt;a href=&#34;http://fifthdown.blogs.nytimes.com/author/brian-burke/&#34;&gt;The Fifth Down Blog&lt;/a&gt;&lt;/span&gt;). So you might be interested on comparing the probability at half time versus his estimated probability which is calculated before the game starts. I mean, maybe you could use the difference between the two to have an idea of how unexpected the first half was. After all, if a game falls outside the pattern it might be worth watching.&lt;/p&gt;
&lt;p&gt;Citations made with &lt;code&gt;knitcitations&lt;/code&gt; (&lt;span class=&#34;showtooltip&#34; title=&#34;Boettiger C (2013). _knitcitations: Citations for knitr markdown  files_. R package version 0.4-4,   https://github.com/cboettig/knitcitations.&#34;&gt;&lt;a href=&#34;https://github.com/cboettig/knitcitations&#34;&gt;Boettiger, 2013&lt;/a&gt;&lt;/span&gt;).&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;lcolladotor, lcollado753. &lt;em&gt;GitHub&lt;/em&gt; &lt;a href=&#34;https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half&#34;&gt;&lt;a href=&#34;https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half&#34;&gt;https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;denishaine, (2013) Veterinary Epidemiologic Research: GLM &amp;amp;ndash; Evaluating Logistic Regression Models (part 3). &lt;em&gt;denis haine&lt;/em&gt; &lt;a href=&#34;http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/&#34;&gt;&lt;a href=&#34;http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/&#34;&gt;http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Advanced NFL Stats. &lt;a href=&#34;http://www.advancednflstats.com/&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/&#34;&gt;http://www.advancednflstats.com/&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(2010) Advanced NFL Stats: Play-by-Play Data. &lt;a href=&#34;http://www.advancednflstats.com/2010/04/play-by-play-data.html&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2010/04/play-by-play-data.html&#34;&gt;http://www.advancednflstats.com/2010/04/play-by-play-data.html&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(2009) Advanced NFL Stats: How the Model Works–A Detailed Example Part 1. &lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html&#34;&gt;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(2009) Advanced NFL Stats: How the Model Works–A Detailed Example Part 2. &lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html&#34;&gt;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;By BURKE, Brian Burke - The Fifth Down Blog - NYTimes.com. &lt;em&gt;The Fifth Down Â» Brian Burke&lt;/em&gt; &lt;a href=&#34;http://fifthdown.blogs.nytimes.com/author/brian-burke/&#34;&gt;&lt;a href=&#34;http://fifthdown.blogs.nytimes.com/author/brian-burke/&#34;&gt;http://fifthdown.blogs.nytimes.com/author/brian-burke/&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Carl Boettiger, knitcitations: Citations for knitr markdown files. &lt;a href=&#34;https://github.com/cboettig/knitcitations&#34;&gt;&lt;a href=&#34;https://github.com/cboettig/knitcitations&#34;&gt;https://github.com/cboettig/knitcitations&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;RStudio , Inc. , (2013) shiny: Web Application Framework for R. &lt;a href=&#34;http://CRAN.R-project.org/package=shiny&#34;&gt;&lt;a href=&#34;http://CRAN.R-project.org/package=shiny&#34;&gt;http://CRAN.R-project.org/package=shiny&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sharing my work for &#34;Advanced Methods III&#34;</title>
      <link>http://lcolladotor.github.io/2013/02/13/sharing-my-work-for-advanced-methods-iii</link>
      <pubDate>Wed, 13 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2013/02/13/sharing-my-work-for-advanced-methods-iii</guid>
      <description>&lt;p&gt;This semester I&amp;#8217;m taking the live version of the Data Analysis class by Jeff Leek. His more &lt;a href=&#34;https://class.coursera.org/dataanalysis-001/class/index&#34;&gt;popular version of the course is available through Coursera&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;One of the things that Jeff promotes is reproducibility and sharing code. I share that tendency and thus created a Git repository for my homework and code for the class: &lt;a href=&#34;http://bit.ly/12vSk7d&#34;&gt;lcollado753&lt;/a&gt;. I&amp;#8217;m hosting it with GitHub to try it out since I started with Mercurial via Bitbucket. &lt;/p&gt;
&lt;p&gt;Part of me would love it if everyone in the class had their own Git repositories. I mean, this class involves lots of practice exercises and there are plenty of R packages and functions that others use that I would like to learn. As I don&amp;#8217;t see this happening, I think that it would be great to list the packages/functions you think could be interesting to others at the end of the write-ups. However, this involves sharing the reports and I don&amp;#8217;t know if that will happen.&lt;/p&gt;
&lt;p&gt;But maybe I didn&amp;#8217;t get the instructions Jeff gave correctly the first time. Listening into his week 2 talks from the Coursera course, I get that he wants our reports to be reproducible. The idea is great, but sometimes I get lots in the technicalities of finding the best fit for our situation. Aka, something we can all do that is worth the time for small scale projects that we have a couple of days to complete and most likely will be finishing the day before they are due. For now we might stick to sharing zip files with the report + summarized data set (it has be small enough to be sharable by email).&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m pretty happy with hosting my stuff at GitHub. One blunder I made in the&lt;a href=&#34;https://github.com/lcolladotor/lcollado753/blob/master/hw/data-analysis-01/report/data01_lcollado.pdf&#34;&gt; first data analysis report&lt;/a&gt; is that I completely forgot to say in it that I have the code in GitHub :P Oh well, next time!&lt;/p&gt;
&lt;p&gt;I feel that I also have lots to improve regarding how to tell a story in a report. Plus, for this first project I mainly did some exploratory data analysis without much stat analysis.&lt;/p&gt;
&lt;p&gt;Overall, I&amp;#8217;m quite excited with this course =) and I think that I&amp;#8217;ll learn a ton on methods to analyze data AND how to actually implement them. Plus, I&amp;#8217;m currently trying to learn ggplot2 as you can see in that first report. Also, I made it with knitr instead of Sweave =)&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to R and Biostatistics (2012 version): presentation</title>
      <link>http://lcolladotor.github.io/2012/11/12/introduction-to-r-and-biostatistics-2012-version</link>
      <pubDate>Mon, 12 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2012/11/12/introduction-to-r-and-biostatistics-2012-version</guid>
      <description>&lt;p&gt;To follow my &lt;a href=&#34;http://fellgernon.tumblr.com/post/34677935591/introducing-r-and-biostatistics-to-first-year-lcg#.UKFlW-Oe918&#34;&gt;Introducing R and Biostatistics to first year LCG students (2012 version)&lt;/a&gt; post,  you can now find the presentation online from my site either in &lt;a href=&#34;http://www.biostat.jhsph.edu/~lcollado/lcg/introR2012/intro_R_Biostat_LCG_2012_slides.html&#34;&gt;presentation format&lt;/a&gt;, in a &lt;a href=&#34;http://www.biostat.jhsph.edu/~lcollado/lcg/introR2012/intro_R_Biostat_LCG_2012.html&#34;&gt;single webpage format&lt;/a&gt;, or the &lt;a href=&#34;http://www.biostat.jhsph.edu/~lcollado/lcg/introR2012/intro_R_Biostat_LCG_2012.Rmd&#34;&gt;raw Rmd file&lt;/a&gt;. To prove the point that publishing to &lt;a href=&#34;http://rpubs.com/&#34;&gt;RPubs&lt;/a&gt; is super easy, you can also find the &lt;a href=&#34;http://rpubs.com/lcollado/2618&#34;&gt;single webpage format over there&lt;/a&gt;. I also like how you can comment and share in RPubs.&lt;/p&gt;
&lt;p&gt;One of the challenges of giving a presentation to first year students is finding the balance between introducing them to cool things you are doing in your work and actually giving a talk that they can follow. I thought about this and ended dropping anything related to my work.&lt;/p&gt;
&lt;p&gt;My presentation was split pretty much in two parts. First, I wanted to promote some philosophical discussion about what is statistics. Second, I gave a brief overview of what you can do with R. Or more exactly, what they should be able to learn to do even if they become &lt;em&gt;wet &lt;/em&gt;biologists.&lt;/p&gt;
&lt;p&gt;While planning this presentation, I knew that I wanted to give the new students a flavor of the three different currents in statistics. I aimed to improve &lt;a href=&#34;http://fellgernon.tumblr.com/post/13739343319/introducing-biostatistics-to-first-year-lcg-students#.UKFl6uOe918&#34;&gt;my 2011 explanations&lt;/a&gt; now that I&amp;#8217;m taking the Foundations of Statistical Inference course. I&amp;#8217;m happy with the result and I think this is greatly due to Royall&amp;#8217;s diagnostic test example.&lt;/p&gt;
&lt;p&gt;Another key point that I wanted to emphasize was that RStudio is the way to go if you are new to R. It is very straightforward to use, plus it is nicely interegrated with &lt;a href=&#34;http://yihui.name/knitr/&#34;&gt;knitr&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I decided to use R Markdown (Rmd) for the first time, after seeing how easy &lt;a href=&#34;http://daringfireball.net/projects/markdown/&#34;&gt;Markdown&lt;/a&gt; really is compared to using LaTeX and Beamer. However, when it got to doing the presentation I have to say that I was a bit dissapointed by how some things just break when using the R Markdown to Markdown to HTML presentation pipeline —using &lt;a href=&#34;http://johnmacfarlane.net/pandoc/&#34;&gt;pandoc&lt;/a&gt; for the last step. For example, the math breaks when using mathml or mathjax at times (like after adding an iframe for a youtube video), so I had to use webtex which doesn&amp;#8217;t look as nice.&lt;/p&gt;
&lt;p&gt;If you are interested in the commands, I used the &amp;#8220;Knit HTML&amp;#8221; button in R Studio [equivalent to running from R: &lt;em&gt;library(knitr); knit(&amp;#8220;filename.Rmd&amp;#8221;)&lt;/em&gt;] and then ran the following command:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;pandoc -s -S &amp;#8212;webtex -i -t dzslides intro_R_Biostat_LCG_2012.md -o intro_R_Biostat_LCG_2012_slides.html &amp;amp; open intro_R_Biostat_LCG_2012_slides.html&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I was originally aiming to have a single Rmd file to produce an HTML presentation and a Beamer presentation. However, controlling the pictures in the Beamer output proved to be challenging. While I had a work around, the final problem was the math part. By the time I realized this it was too late —I just dropped the Beamer presentation. Googling, even the author of knitr acknowledges that the best input for PDF output is still LaTeX.&lt;/p&gt;
&lt;p&gt;In the end, I&amp;#8217;m happy that I got the HTML presentation done using R Markdown and briefly introduced it to the first year students. The basics of knitr are very easy to learn and I&amp;#8217;m hoping that it got some of them curious enough to try it.&lt;/p&gt;
&lt;p&gt;Next thing in line: prepare 5 questions for the students.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing R and Biostatistics to first year LCG students (2012 version)</title>
      <link>http://lcolladotor.github.io/2012/10/30/introducing-r-and-biostatistics-to-first-year-lcg</link>
      <pubDate>Tue, 30 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2012/10/30/introducing-r-and-biostatistics-to-first-year-lcg</guid>
      <description>&lt;p&gt;&lt;p&gt;On Friday November 9th I&amp;#8217;ll be giving a talk to the first year students from the Undergraduate Program on Genomic Sciences (LCG in Spanish) during their &amp;#8220;Seminar 1: Introduction to Bioinformatics&amp;#8221; course. It&amp;#8217;s just like I did a year ago as I documented in my post &lt;a href=&#34;http://fellgernon.tumblr.com/post/13739343319/introducing-biostatistics-to-first-year-lcg-students#.UJBq6Wl25FQ&#34;&gt;Introducing Biostatistics to first year LCG students&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Well, this time I&amp;#8217;ll change things a bit. I&amp;#8217;m allowed to require the students to read 2-3 papers before my talk to introduce them to my field. I&amp;#8217;ll do so, but in a more peculiar way by requiring them to listen in to a few videos I selected. So, without further ado here are the three required &amp;#8220;papers&amp;#8221;:&lt;/p&gt;
&lt;p&gt;Here is &amp;#8220;&lt;strong&gt;paper 1&lt;/strong&gt;&amp;rdquo; (~30 minutes). The goal is to introduce you to the basic workings of R and also to great sources of R videos.&lt;/p&gt;
&lt;p&gt;First, learn to install R (watch it in full screen).&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;305&#34; src=&#34;http://www.screenr.com/embed/kzT8&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Or you can also watch any of the two following videos:&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;281&#34; src=&#34;http://www.youtube.com/embed/Icawuhf0Yqo&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;281&#34; src=&#34;http://www.youtube.com/embed/mfGFv-iB724&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Next learn about RStudio and why it&amp;#8217;s a great place to start (watch it on hd and fullscreen).&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;281&#34; src=&#34;http://www.youtube.com/embed/JbTMvQ-SbvQ&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Now you are ready to learn how to create a variable in R. Use RStudio instead of the R GUI to do so.&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;305&#34; src=&#34;http://www.screenr.com/embed/qyT8&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Next, learn the super basics about the basic R plot system.&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;305&#34; src=&#34;http://www.screenr.com/embed/XeS8&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Now you are ready to learn about how to use the combine function.&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;305&#34; src=&#34;http://www.screenr.com/embed/jyT8&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Next, learn about data.frame type of objects&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;305&#34; src=&#34;http://www.screenr.com/embed/fCs8&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;and how to add new variables to them.&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;305&#34; src=&#34;http://www.screenr.com/embed/ge28&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Next up is learning how to find help.&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;305&#34; src=&#34;http://www.screenr.com/embed/Pps8&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Almost there. Now check how to change your current working directory.&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;281&#34; src=&#34;http://www.youtube.com/embed/8xT3hmJQskU&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Finally, learn how to install and load a package in R.&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;396&#34; src=&#34;http://www.screenr.com/embed/Fps8&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;If you are more curious regarding the origins of R check the next video (not part of &amp;#8220;paper 1&amp;#8221;).&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;281&#34; src=&#34;http://www.youtube.com/embed/kzxHxFHW6hs&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Next, &amp;#8220;&lt;strong&gt;paper 2&lt;/strong&gt;&amp;rdquo; (~39 minutes). The goal here is to get a feeling of how you can use R to create plots.&lt;/p&gt;
&lt;p&gt;First start with this demonstration of the basic R plotting tools (called &amp;#8220;base graphics&amp;#8221;). It does in enough level of detail of how the basic plotting system works and how you can customize the colors, layout, etc. For the purpose of getting used to the tool, I recommend that you follow this video using RStudio. Also, you&amp;#8217;ll want to watch it in 720p.&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;281&#34; src=&#34;http://www.youtube.com/embed/4KLfzsj-qkE&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Now check the demo for plotting with the &lt;em&gt;lattice&lt;/em&gt; package. This is more advanced, but it should also be more illustrative of the power you have with R. Plus it shows how we can expand the functionality of R by using packages contributed to the community and freely available for us to use.&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;281&#34; src=&#34;http://www.youtube.com/embed/6VP5JBq1g7g&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Finally, &amp;#8220;&lt;strong&gt;paper 3&lt;/strong&gt;&amp;rdquo; (~28 minutes). This is the first lecture from a course by Brian Caffo in which he goes over the definition and overall motivation behind Biostatistics. It should be much more fun to watch than reading a review paper in the area.&lt;/p&gt;
&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;281&#34; src=&#34;http://www.youtube.com/embed/jkUqDVtpKs4&#34; width=&#34;500&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Now, for those motivated to learn more, I recommend some of my own posts summarizing  information that can be useful to you.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;http://fellgernon.tumblr.com/post/32688589475/jhsph-biostat-through-coursera#.UJBzBml25FQ&#34;&gt;JHSPH-Biostat through Coursera&lt;/a&gt; and &lt;a href=&#34;http://fellgernon.tumblr.com/post/33114381084/an-online-bioinformatics-curriculum#.UJBy92l25FQ&#34;&gt;An Online Bioinformatics Curriculum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://fellgernon.tumblr.com/post/30077689805/setting-up-your-computer-for#.UJBzO2l25FQ&#34;&gt;Setting up your computer for bioinformatics/biostatistics and a compedium of resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://fellgernon.tumblr.com/post/30970426274/i-consider-myself-a-fan-of-using-version-control#.UJBzKml25FQ&#34;&gt;Motivation behind using a version control system&lt;/a&gt; and &lt;a href=&#34;http://fellgernon.tumblr.com/post/32198487580/introducing-git-while-making-your-academic-webpage#.UJBzIGl25FQ&#34;&gt;Introducing Git while making your academic webpage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://fellgernon.tumblr.com/post/33162495473/why-arent-all-of-our-graphs-interactive#.UJBy8ml25FQ&#34;&gt;Why aren’t all of our graphs interactive?&lt;/a&gt; and &lt;a href=&#34;http://fellgernon.tumblr.com/post/33908652237/visualizing-colors#.UJBy6Gl25FQ&#34;&gt;Visualizing colors()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://fellgernon.tumblr.com/post/16763819010/p-values-and-statistics-phylosophy#.UJB0j2l25FQ&#34;&gt;P-values and Statistics phylosophy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://fellgernon.tumblr.com/post/13830203652/the-new-visualization-package-for-genome-data-in#.UJB04Wl25FQ&#34;&gt;The new visualization package for genome data in Bioconductor: ggbio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Sources:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;http://www.twotorials.com/&#34;&gt;&lt;a href=&#34;http://www.twotorials.com/&#34;&gt;http://www.twotorials.com/&lt;/a&gt;&lt;/a&gt; by &lt;a href=&#34;http://www.kaiseredu.org/tutorials-and-presentations/bios/anthony-damico.aspx&#34;&gt;Anthony Damico&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.youtube.com/user/rdpeng?feature=results_main&#34;&gt;Youtube videos&lt;/a&gt; by &lt;a href=&#34;http://www.biostat.jhsph.edu/~rpeng/&#34;&gt;Roger Peng&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.youtube.com/user/bcaffo?feature=results_main&#34;&gt;Youtube videos&lt;/a&gt; by &lt;a href=&#34;http://www.bcaffo.com/&#34;&gt;Brian Caffo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing colors()</title>
      <link>http://lcolladotor.github.io/2012/10/19/visualizing-colors</link>
      <pubDate>Fri, 19 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2012/10/19/visualizing-colors</guid>
      <description>&lt;p&gt;The other day I learnt about the existance of the colors() vector in R which specifies all the character-based colors like &amp;#8220;light blue&amp;#8221;, &amp;#8220;black&amp;#8221;, etc. So I made a simple plot to visualize them all. Here&amp;#8217;s the code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mat &amp;lt;- matrix(1:length(colors()), ncol = 9, byrow= TRUE)
df &amp;lt;- data.frame(col = colors(), 
	x = as.integer(cut(1:length(colors()), 9)),
	y = rep(1:73, 9), stringsAsFactors=FALSE)
plot(y ~ jitter(x), data = df, col = df$col,
 	pch=16, main = &amp;quot;Visualizing colors() split in 9 groups&amp;quot;,
 	xlab = &amp;quot;Group&amp;quot;, 
	ylab = &amp;quot;Element of the group (min = 1, max = 73)&amp;quot;,
	sub = &amp;quot;x = 3, y = 1 means that it&#39;s the 2 * 73 + 1 = 147th color&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And the plot:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://media.tumblr.com/tumblr_mc5ovbt4uQ1qfs0hy.png&#34;/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why aren&#39;t all of our graphs interactive?</title>
      <link>http://lcolladotor.github.io/2012/10/08/why-arent-all-of-our-graphs-interactive</link>
      <pubDate>Mon, 08 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2012/10/08/why-arent-all-of-our-graphs-interactive</guid>
      <description>&lt;p&gt;During the last pre-happy hour seminar, &lt;a href=&#34;http://www.biostat.wisc.edu/~kbroman/&#34;&gt;Karl Broman&lt;/a&gt; talked about &lt;a href=&#34;http://www.biostat.wisc.edu/~kbroman/presentations/DynamicGraphs/&#34;&gt;Why aren&amp;#8217;t all of our graphs interactive?&lt;/a&gt; I didn&amp;#8217;t know, but a few years ago Karl worked in the department and clearly promoted beer-drinking and is &lt;em&gt;the heart of the department. &lt;/em&gt;I&amp;#8217;m a fan of our pre-happy hour seminars since you have a get to listen to good/fun talks over a beer or two.&lt;/p&gt;
&lt;p&gt;But I&amp;#8217;m also a fan of reproducible research and useful graphics. I do most of this by using &lt;a href=&#34;http://www.statistik.lmu.de/~leisch/Sweave/&#34;&gt;Sweave&lt;/a&gt; (for reproducibility) in LaTeX documents and with the R packages &lt;a href=&#34;http://cran.r-project.org/web/packages/lattice/index.html&#34;&gt;lattice&lt;/a&gt;, &lt;a href=&#34;http://cran.r-project.org/web/packages/car/index.html&#34;&gt;car&lt;/a&gt;, and &lt;a href=&#34;http://cran.r-project.org/web/packages/plotrix/index.html&#34;&gt;plotrix&lt;/a&gt;, and some &lt;a href=&#34;http://ggplot2.org/&#34;&gt;ggplot2&lt;/a&gt; (I should use it more). &lt;/p&gt;
&lt;p&gt;Karl made &lt;a href=&#34;http://www.biostat.wisc.edu/~kbroman/presentations/DynamicGraphs/&#34;&gt;his presentation&lt;/a&gt; using html (definitely check it out!) and inserted pretty interactive graphics. His talk got me really interested and I definitely need to pick up a few tools. For example, asciidoc or R Markdown can be useful for making html documents with R code. Specially if you want to write a report and you don&amp;#8217;t want to deal with Sweave/Latex when making plots (can be a pain to know where they&amp;#8217;ll show up). &lt;/p&gt;
&lt;p&gt;For the interactive side, D3 (and other tools Karl listed) can be useful to learn. But I might put this on a hold for some time. Maybe I&amp;#8217;ll wait and see what others in the deparment are developing for R-D3 and embedding interactive plots in pdf files.&lt;/p&gt;
&lt;p&gt;I don&amp;#8217;t think that it will be long before interactive plots make it to the journals. Specially for their web versions. Though, I still think that if you are showing a 3D plot, as the author you will have to give a few default views where you can clearly see something that you want to talk about instead of having the reader find that sweet spot. &lt;/p&gt;
&lt;p&gt;One problem that I don&amp;#8217;t think has been solved yet is reproducible research on a cluster. Karl and others mentioned &lt;a href=&#34;http://www.gnu.org/software/make/manual/make.html&#34;&gt;make&lt;/a&gt; as well as having if/else clauses where you either show the output or a cleaned up version of the code that you used to generate the output. &lt;/p&gt;
&lt;p&gt;Overall, there are many tools and tips I can learn from Karl. And I&amp;#8217;m sure that I&amp;#8217;m not the only one! Hopefully he&amp;#8217;ll give tips on where to start (nothing is more tedious than reading UNIX man-files).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>JHSPH-Biostat through Coursera</title>
      <link>http://lcolladotor.github.io/2012/10/01/jhsph-biostat-through-coursera</link>
      <pubDate>Mon, 01 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2012/10/01/jhsph-biostat-through-coursera</guid>
      <description>&lt;p&gt;Have you heard of online education? If you are in the US or Mexico I&amp;#8217;m sure that you have seen some ads about online universities. Well, that&amp;#8217;s not the type of education I&amp;#8217;m talking about. I&amp;#8217;m talking about free high-quality education. &lt;/p&gt;
&lt;p&gt;For some years, the top option has been the &lt;strong&gt;O&lt;/strong&gt;pen &lt;strong&gt;C&lt;/strong&gt;ourse&lt;strong&gt;w&lt;/strong&gt;are (OCW) organized under the &lt;a href=&#34;http://www.ocwconsortium.org/&#34;&gt;Open Courseware Consortium&lt;/a&gt; (OCWC). Back in 2009 I was pushed my undergrad (LCG-UNAM) to design and teach OCW-compliant courses. I even taught a &lt;a href=&#34;http://www.lcg.unam.mx/~lcollado/B/index_en.html&#34;&gt;course on R/Bioconductor&lt;/a&gt; and thought of it as a pilot OCW course. The first seven classes were video recorded. But that project hit a wall because many of the biology professors used slides that heavily relied on copyrighted material. For OCW courses you have to own the copyright of the material that you use (or get permission), so just the idea of having to re-do all the diagrams and figures was overwhelming. This hasn&amp;#8217;t stopped some big universities like &lt;a href=&#34;http://ocw.mit.edu/index.htm&#34;&gt;MIT from publishing OCW-compliant courses&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Recently there&amp;#8217;s been talk of the new horse in the race: &lt;a href=&#34;https://www.coursera.org/&#34;&gt;Coursera&lt;/a&gt;. What is it? Well, &lt;a href=&#34;https://www.coursera.org/about&#34;&gt;according to themselves&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We are a social entrepreneurship company that partners with the top universities in the world to offer courses online for anyone to take, for free. We envision a future where the top universities are educating not only thousands of students, but millions. Our technology enables the best professors to teach tens or hundreds of thousands of students.&lt;/p&gt;
&lt;p&gt;Through this, we hope to give everyone access to the world-class education that has so far been available only to a select few. We want to empower people with education that will improve their lives, the lives of their families, and the communities they live in.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So far, the motivation is similar to the OCW movement. However, one very big difference is that Coursera &lt;strong&gt;does offer certificates&lt;/strong&gt;. Something which OCW courses do not. For example, &lt;a href=&#34;http://ocw.mit.edu/about/&#34;&gt;MIT-OCW&lt;/a&gt; says:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;OCW is not an MIT education.&lt;/li&gt;
&lt;li&gt;OCW does not grant degrees or certificates.&lt;/li&gt;
&lt;li&gt;OCW does not provide access to MIT faculty.&lt;/li&gt;
&lt;li&gt;Materials may not reflect entire content of the course.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Coursera courses do provide the entire content of the course. Well, this is slightly tricky since some professors use the same base material in the university-in-class courses but expand it beyond what is available through Coursera. Thus in a sense Coursera are more accesible courses with lesser requirements than the in-class versions. But compared to OCW, you have homeworks (which are graded) and can communicate with the faculty through the use of forums.&lt;/p&gt;
&lt;p&gt;One advantage of OCW courses is that you can look at them whenever you want. For Coursera ones you have to sign up (and thus register to their system) and they are open for certain periods of time.&lt;/p&gt;
&lt;p&gt;Currently, the Biostatistics Department at JHSPH is offering three courses through Coursera. These are &lt;a href=&#34;https://www.coursera.org/course/compdata&#34;&gt;Computing for Data Analysis&lt;/a&gt; by &lt;a href=&#34;http://www.biostat.jhsph.edu/~rpeng/&#34;&gt;Roger D. Peng&lt;/a&gt;, &lt;a href=&#34;https://www.coursera.org/course/biostats&#34;&gt;Mathematical Biostatistics Boot Camp&lt;/a&gt; by &lt;a href=&#34;http://www.bcaffo.com/&#34;&gt;Brian Caffo&lt;/a&gt;, and &lt;a href=&#34;https://www.coursera.org/course/dataanalysis&#34;&gt;Data Analysis&lt;/a&gt; by &lt;a href=&#34;http://www.biostat.jhsph.edu/~jleek/&#34;&gt;Jeffrey Leek&lt;/a&gt;. The first two are introductory courses to using R and Biostatistics, respectively. I&amp;#8217;m taking the in-class versions and highly recommend them to anyone that wants to get started in either topic. They both involve youtube videos and practice exercises. The videos themselves are great since they rehearse what they are going to say, used a high-quality audio recording room, tuned the audio, and included highlights in the slides so you can follow them easily. &lt;strong&gt;Right now you can go and sign up for these two courses!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The third one, Data Analysis, is more advanced and I&amp;#8217;ll take it in-class next year. In addition, for now the sign up is closed for 2012 (you can go ahead and save a spot for 2013). &lt;/p&gt;
&lt;p&gt;All of these courses have a couple thousands students registered, which is great! I&amp;#8217;m sure that the great majority will greatly benefit from them. To finish my post, I&amp;#8217;ll leave you with their short introduction videos, which will tell you more than what I can via text!&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;

&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;253&#34; src=&#34;http://www.youtube.com/embed/gk6E57H6mTs&#34; width=&#34;450&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;

&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;253&#34; src=&#34;http://www.youtube.com/embed/ekdpaf_WT_8&#34; width=&#34;450&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;

&lt;p&gt;&lt;iframe frameborder=&#34;0&#34; height=&#34;253&#34; src=&#34;http://www.youtube.com/embed/-lutj1vrPwQ&#34; width=&#34;450&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up your computer for bioinformatics/biostatistics and a compedium of resources</title>
      <link>http://lcolladotor.github.io/2012/08/23/setting-up-your-computer-for</link>
      <pubDate>Thu, 23 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2012/08/23/setting-up-your-computer-for</guid>
      <description>&lt;p&gt;Jumping on the train set by &lt;a href=&#34;http://www.biostat.jhsph.edu/~hiparker/&#34;&gt;Hilary Parker&lt;/a&gt; &amp;#8220;&lt;a href=&#34;http://hilaryparker.com/2012/08/16/the-setup-part-1/&#34;&gt;The Setup (Part 1)&lt;/a&gt;&#34; and &lt;a href=&#34;http://biostat.jhsph.edu/~afrazee/&#34;&gt;Alyssa Frazee&lt;/a&gt; &amp;#8220;&lt;a href=&#34;http://alyssafrazee.wordpress.com/&#34;&gt;my software/hardware setup&lt;/a&gt;&amp;#8221;, I&amp;#8217;m going to share my setup and hopefully add something new. They both did a great job already, so make sure you read their posts!&lt;/p&gt;
&lt;p&gt;I have some experience with all three main OS: Windows, Linux and Mac. That being said, I know some of the basic stuff for each but I surely use Google very frequently to get help. I used to have a dual Windows / Linux (Ubuntu) set up but now I have a Windows laptop/desktop (it&amp;#8217;s a monster :P) at home and I&amp;#8217;m happy working with my Mac. &lt;/p&gt;
&lt;p&gt;I&amp;#8217;m going to start by mentioning the software I use(d) in each OS and then add some other tools that I really like.&lt;/p&gt;
&lt;p&gt;Windows&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Text editor: &lt;a href=&#34;http://notepad-plus-plus.org/&#34;&gt;Notepad++&lt;/a&gt;. It outperforms Notepad by light years! A must for me is the &amp;#8220;View -&amp;gt; Word wrap&amp;#8221; option. I would definitely go to &amp;#8220;Settings -&amp;gt; Preferences -&amp;gt; New Document/Default Directory&amp;#8221; and change the new document format from Windows (Dos) to Unix. This will save you time later when you want to work on a Unix system like the cluster. If you didn&amp;#8217;t, you can change a specific document&amp;#8217;s EOL (end of line) by using &amp;#8220;Edit -&amp;gt; EOL conversion -&amp;gt; UNIX format&amp;#8221;. Another feature that I like is the &amp;#8220;Search -&amp;gt; Replace&amp;#8230;&amp;#8221; which allows you to use regular expressions (like Perl). &lt;/li&gt;
&lt;li&gt;Statistical software: &lt;a href=&#34;http://cran.r-project.org/&#34;&gt;R&lt;/a&gt; of course! It&amp;#8217;s best to do a custom installation and choose a directory without spaces in it. That will help later (further below). If you want to be convinced to join the R community read &lt;a href=&#34;http://www.nytimes.com/2009/01/07/technology/business-computing/07program.html?_r=3&amp;amp;scp=1&amp;amp;sq=robert%20gentleman&amp;amp;st=cse&#34;&gt;Data Analysits Captivated by R&amp;#8217;s power&lt;/a&gt; and &lt;a href=&#34;http://bits.blogs.nytimes.com/2009/01/08/r-you-ready-for-r/?scp=1&amp;amp;sq=Robert%20Gentleman&amp;amp;st=cse&#34;&gt;R You Ready for R?&lt;/a&gt; or just take a look at what others are using. Remember that the R project is open source, free and easy to contribute to. If you end up choosing Excel as your statistical software, well, there is &lt;strong&gt;no&lt;/strong&gt; hope for you!!&lt;/li&gt;
&lt;li&gt;R code editor: Notepad++ with &lt;a href=&#34;http://sourceforge.net/projects/npptor/&#34;&gt;NppToR&lt;/a&gt;. For a long time I used Emacs modified to work with Windows by Vincent Goulet available &lt;a href=&#34;http://vgoulet.act.ulaval.ca/en/emacs/&#34;&gt;here&lt;/a&gt;. It works great and saves you quite a bit of setup time. &lt;a href=&#34;http://www.xemacs.org/&#34;&gt;XEmacs&lt;/a&gt; is another option that a friend of mine used, but it never convinced me. Anyhow, I ended up changing from Emacs to Notepad++ with NppToR because I could:&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;Force quit R (and not lose code changes) in case I crashed R by doing something stupid like printing something huge or w/e :P &lt;/li&gt;
&lt;li&gt;Access help pages in a separate window. I&amp;#8217;m sure you can do it too with Emacs, but I was just lazy to configure it.&lt;/li&gt;
&lt;li&gt;Shorter shortcuts&lt;/li&gt;
&lt;li&gt;Later on I found the NppToR to PuTTy feature which is very useful.&lt;/li&gt;
&lt;li&gt;You can create an R syntax dictionary (or something like that) in Notepad++ which will scan all your R packages and add the function names so they are colored when you type them. Also Notepad++ will auto-complete some function names and show you the arguments. Great stuff! (Forgot the name, so&amp;#8230; google it :P)&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;SSH: &lt;a href=&#34;http://www.chiark.greenend.org.uk/~sgtatham/putty/&#34;&gt;PuTTY&lt;/a&gt;. As said before, works well with Notepad++ and NppToR.&lt;/li&gt;
&lt;li&gt;SCP: &lt;a href=&#34;http://winscp.net/eng/index.php&#34;&gt;WinSCP&lt;/a&gt;. There are others that work too like &lt;a href=&#34;http://filezilla-project.org/&#34;&gt;Filezilla&lt;/a&gt; but well, WinSCP does the job well.&lt;/li&gt;
&lt;li&gt;PDF viewer: &lt;a href=&#34;http://www.adobe.com/products/acrobatpro.html&#34;&gt;Adobe Acrobat Professional&lt;/a&gt;. I&amp;#8217;m using the X version now. I like how I can highlight, underline, cross out, free hand, sticky note, combine files into a single pdf, combine pdfs, and change the highlight colors easily. It also has a change tracker (kind of like Word has). I&amp;#8217;ve seen other use PDF Annotator which is available for free for Hopkins students. Anyhow, I simply love Acrobat for reading papers.&lt;/li&gt;
&lt;li&gt;LaTeX: &lt;a href=&#34;http://miktex.org/&#34;&gt;MiKTeX&lt;/a&gt;. For writing TeX files I used either Emacs or Notepad++. There is another software which has drop down menus and the like called &lt;a href=&#34;http://www.winedt.com/&#34;&gt;WinEdt&lt;/a&gt;. I got used to typing LaTeX from scratch, well, I have a template.Rnw somewhere. Oh yeah, I always use Sweave when writing TeX files (even if I don&amp;#8217;t use R). &lt;/li&gt;
&lt;li&gt;R reports: &lt;a href=&#34;http://www.statistik.lmu.de/~leisch/Sweave/&#34;&gt;Sweave by Friedrich Leisch&lt;/a&gt;, one of the champions of reproducibility! To learn more about Sweave first &lt;a href=&#34;http://stat.epfl.ch/webdav/site/stat/shared/Regression/EPFL-Sweave-powerdot.pdf&#34;&gt;read this pdf&lt;/a&gt; by Nicola Sartori. This is another &lt;a href=&#34;http://users.stat.umn.edu/~geyer/Sweave/foo.pdf&#34;&gt;Sweave demo&lt;/a&gt; by Charles J Geyer. Check out this great &lt;a href=&#34;http://www.johndcook.com/troubleshooting_sweave.html&#34;&gt;Windows Sweave troubleshooting page&lt;/a&gt; by John D Cook.&lt;/li&gt;
&lt;li&gt;Building R packages from source. You will definitely need &lt;a href=&#34;http://cran.fhcrc.org/bin/windows/Rtools/&#34;&gt;Rtools&lt;/a&gt; installed. I would also install &lt;a href=&#34;http://qpdf.sourceforge.net/&#34;&gt;QPDF&lt;/a&gt; which can be used by R to compress your pdf files, which is a good thing if you want to have a small-sized tarball. Last but not least, check out &lt;a href=&#34;http://robjhyndman.com/researchtips/building-r-packages-for-windows/&#34;&gt;Building R packages for Windows&lt;/a&gt; by Rob J Hyndman.&lt;/li&gt;
&lt;li&gt;Learn to modify your PATH! Check 1.3 from the previous link by Rob J Hyndman. If you are going to use Sweave, it&amp;#8217;s best to add to your PATH the path for the directory containing your Sweave.sty file so that you won&amp;#8217;t need to copy it to every single directory. This is why it pays off to do an R custom installation and put it in C:/R/R-current-version or something like that instead of C:/Program Files/ bla bla with spaces. It used to be more important a few years ago. Also, I created a sw.bat file and put it somewhere where my PATH would find it. That sw.bat file ran Sweave, pdflatex twice, then bibtex and finally opened the pdf file.&lt;/li&gt;
&lt;li&gt;PDF viewer for LaTeX files. I only learnt about pdf sync and the like a year ago. You should google how to set this up with SumatraPDF (Adobe Acrobat doesn&amp;#8217;t work!).&lt;/li&gt;
&lt;li&gt;Version control: &lt;a href=&#34;http://mercurial.selenic.com/&#34;&gt;Mercurial&lt;/a&gt;. It&amp;#8217;s very easy to use and you can get an account at &lt;a href=&#34;https://bitbucket.org/&#34;&gt;Bitbucket.org&lt;/a&gt; with unlimited number of private repositories if you have an academic email. Even if you are not doing a collaborative project, you will love using a version control system! It will clean up your directories very nicely and will help you become more organized. Learning a few commands is nothing compared to having lots of files with _v1 v_2, etc at the end. Check out the &lt;a href=&#34;http://mercurial.selenic.com/guide/&#34;&gt;Mercurial guide&lt;/a&gt; to get started. Note that for windows instead of customizing your .hgrc file you will customize a mercurial.ini file.&lt;/li&gt;
&lt;li&gt;Presentations: both PowerPoint and &lt;a href=&#34;http://en.wikipedia.org/wiki/Beamer_(LaTeX)&#34;&gt;Beamer&lt;/a&gt; (normally with Sweave too). Rarely I use &lt;a href=&#34;https://docs.google.com&#34;&gt;Google Docs&lt;/a&gt; for this.&lt;/li&gt;
&lt;li&gt;Office: Either Microsoft Office or &lt;a href=&#34;http://www.openoffice.org/&#34;&gt;OpenOffice&lt;/a&gt; (free).&lt;/li&gt;
&lt;li&gt;Poster creator: &lt;a href=&#34;http://www.postergenius.com/cms/index.php&#34;&gt;PosterGenius&lt;/a&gt; (academic discount price). It was very easy to use and I would surely give the free trial version a go. It adds a watermark, but well, you will appreciate the time you save compared to using PowerPoint. I guess that &lt;a href=&#34;http://www.adobe.com/products/photoshop.html&#34;&gt;Adobe Photoshop&lt;/a&gt; is another option, but I&amp;#8217;ve only used it to edit photos here and there, not to make a whole poster. The most I did was create &lt;a href=&#34;https://picasaweb.google.com/lh/photo/NUiUno0H6MZ8dfTN8ZqF9yRO-Af4bmaijyeT4dbBml0?feat=embedwebsite&#34;&gt;this&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To de-compress RAR files: &lt;a href=&#34;http://www.win-rar.com/start.html?&amp;amp;L=0&#34;&gt;WinRAR&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Anti-spyware: &lt;a href=&#34;http://www.avast.com/free-antivirus-download&#34;&gt;Avast&lt;/a&gt; (free version). I normally keep it in silent (gaming) mode so it doesn&amp;#8217;t show pop ups.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cccp-project.net/&#34;&gt;CCCP codec pack&lt;/a&gt; which includes the Media Player Classic. Great for watching video files and dumping the crappy Windows Media Player.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Linux (Ubuntu)&lt;/p&gt;

&lt;p&gt;Ubuntu provides Linux distributions that are very user friendly and that look much like Mac OS does now. You&amp;#8217;ll find it easy to run multi-core programs which were a pain to do with Windows. Beware that even if you use Ubuntu you will need to learn stuff like how to compile. Also, please check before you install that your computer is supported. For example, some laptops with very new video cards might not work properly. That being said, with Ubuntu you will feel very at ease working in an area like mine (genomics) because a lot of the software runs in Linux (normally in a cluster, but you can test in your lap).&lt;/p&gt;
&lt;p&gt;You will want to check and/or keep for reference &lt;a href=&#34;http://faculty.ucr.edu/~tgirke/Documents/UNIX/linux_manual.html&#34;&gt;LINUX Essentials&lt;/a&gt; by Thomas Girke (more from him below), &lt;a href=&#34;http://freeengineer.org/learnUNIXin10minutes.html&#34;&gt;Learn Linux in 10 minutes&lt;/a&gt;, &lt;a href=&#34;http://www.linux-tutorial.info/toc&#34;&gt;The Linux tutorial&lt;/a&gt;, and &lt;a href=&#34;http://www.basicconfig.com/linux/vi&#34;&gt;Linux vi editor tutorial&lt;/a&gt;.  &lt;/p&gt;
* If you are going to use Linux (Ubuntu) at some point you will want to compile something from source and find out that you are missing a dependency. That&amp;#8217;s when I google, then use&amp;#160;:
1. apt-cache search something
2. sudo apt-get install something 

* Note that you will frequently need the yyyy-devel version which includes c headers and stuff that you need to compile.
* You will find a lot of things through the package installer (forgot what it&amp;#8217;s called). Learn the pseudonym for your Ubuntu version so you select the appropriate version of the software in case that you are downloading it from another place.
* SSH/SCP: terminal commands :) I just wanted to mention that rsync is a nice command for synching folders (recursively too) between your computer and say the cluster.
* Version control: Mercurial again. The configuration file is .hgrc not mercurial.ini
* Text editor: Nedit or Emacs. Vi when doing in-terminal modifications.
* You can get R through aptitude or if you want the very latest (or a devel version) you&amp;#8217;ll have to compile it. The first time you will have to install plenty of dependencies, but it&amp;#8217;s good practice.
* Office: go with OpenOffice.
* LaTeX: install the texlive distribution. I normally get everything so that later when I&amp;#8217;m trying to use a TeX package I won&amp;#8217;t have to go install it (which is what MiKTeX does for you in Windows). 
* Video player: VLC.

&lt;p&gt;Mac&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Terminal: &lt;a href=&#34;http://www.iterm2.com&#34;&gt;iTerm2&lt;/a&gt;. Mac comes with a native terminal, but iTerm2 has other nice functions like tabs and more options to customize it. Check &lt;a href=&#34;http://code.google.com/p/iterm2/wiki/ColorGallery&#34;&gt;this&lt;/a&gt; for free color palettes. I like the Homebrew one from &lt;a href=&#34;https://github.com/mbadolato/iTerm2-Color-Schemes&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;LaTeX and R editor: &lt;a href=&#34;http://aquamacs.org/&#34;&gt;Aquamacs&lt;/a&gt; is a version of Emacs that works great. However, as I discussed in the Windows section I&amp;#8217;m moving away from Emacs. Well, to be honest, I don&amp;#8217;t want to put the time to learn how to customize Emacs properly and do amazing stuff with it like Kasper does. Recently (since June) I&amp;#8217;ve been using &lt;a href=&#34;http://macromates.com/&#34;&gt;TextMate&lt;/a&gt;. It has this thing called &amp;#8220;Bundles&amp;#8221; which provides different hotkeys depending on the file you are editing. Meaning that for Rnw files you can Sweave them directly there and for R files you can either send the code to R or to the terminal (much like Notepad++). The one thing is that it is not free BUT there is a 2.0 alpha release &lt;a href=&#34;https://github.com/textmate/textmate&#34;&gt;available on github&lt;/a&gt; that you can compile. &lt;a href=&#34;http://developers.slashdot.org/story/12/08/09/1947234/textmate-2-released-as-open-source&#34;&gt;This lengthly discussion&lt;/a&gt; can be worth reading if you want to know more about the 2.0 version and the future of TextMate. Someone said there that &lt;a href=&#34;http://www.sublimetext.com/&#34;&gt;Sublime&lt;/a&gt; might be replacing TextMate but I haven&amp;#8217;t looked for any R integration in it. Anyhow, I liked how TextMate included an auto-spell checker that recognizes Sweave/LaTeX code from the box :)&lt;/li&gt;
&lt;li&gt;Package installer: &lt;a href=&#34;http://www.macports.org/&#34;&gt;MacPorts&lt;/a&gt;. It&amp;#8217;s kind of similar to aptitude from Linux but it&amp;#8217;s Mac only. Note that you will definitely need to get &lt;a href=&#34;https://developer.apple.com/xcode/&#34;&gt;XCode&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;PDF viewer: also Adobe Acrobat Pro for the reasons mentioned previously.&lt;/li&gt;
&lt;li&gt;PDF viewer for LaTeX: TeXShop which I think comes with the MacTeX distribution. It has the forward sync that Alyssa mentions in her blog.&lt;/li&gt;
&lt;li&gt;Text editor: &lt;a href=&#34;http://www.barebones.com/products/TextWrangler/&#34;&gt;TextWrangler&lt;/a&gt;. Has several of the functions I talked about in the Notepad++ section like search and replace with regular expressions. It definitely outperforms the native text editor.&lt;/li&gt;
&lt;li&gt;SCP: &lt;a href=&#34;http://cyberduck.ch&#34;&gt;Cyberduck&lt;/a&gt;. I haven&amp;#8217;t tried others, but it works and I&amp;#8217;m happy with it. I also use the terminal to push/retrieve files like I would do in Linux. Same for ssh and Mercurial.&lt;/li&gt;
&lt;li&gt;Version control: Mercurial. Note that you might have to add a site key (like bitbucket&amp;#8217;s) to your .hgrc file so it doesn&amp;#8217;t complain when pushing files.&lt;/li&gt;
&lt;li&gt;Productivity: &lt;a href=&#34;http://itunes.apple.com/us/app/my-little-pomodoro/id412699095?mt=12&#34;&gt;My Little Pomodoro&lt;/a&gt; available from the Mac app store. I love it for following the Pomodoro technique (you can use any other timer that you like) which Hilary introduced me to. It works like a charm when you are under stress and need to be productive. After all, I&amp;#8217;m prone to escape the stress and distract myself, so this helps me keep my distractions limited. I&amp;#8217;ve also found that when I&amp;#8217;m stuck in a problem and I take the 5 min break thinking about something else, well, the machine keeps working and when I come back from the break I have a new idea to try out.&lt;/li&gt;
&lt;li&gt;Video player: &lt;a href=&#34;http://www.videolan.org/vlc/index.html&#34;&gt;VLC&lt;/a&gt; (includes codecs).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other stuff&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Browser: I used to love&lt;a href=&#34;http://www.mozilla.org/en-US/&#34;&gt;Mozilla Firefox&lt;/a&gt; (it has a nice sync functionality) but I&amp;#8217;ve moved to &lt;a href=&#34;https://www.google.com/intl/en/chrome/browser/&#34;&gt;Google Chrome&lt;/a&gt;. It&amp;#8217;s kind of a shame that Google started to compete with Mozilla, but oh well bye bye 2007. I use Chrome because it works a tad bit better with other Google tools, but that&amp;#8217;s it. It also syncs your bookmarks. Both work great and &lt;a href=&#34;http://www.opera.com/&#34;&gt;Opera&lt;/a&gt; is still my favorite backup browser. I guess anything but Internet Explorer and Safari.&lt;/li&gt;
&lt;li&gt;Learning R. I would definitely check Thomas Girke &lt;a href=&#34;http://manuals.bioinformatics.ucr.edu/home/programming-in-r&#34;&gt;Programming in R&lt;/a&gt; page and Frank McCown&amp;#8217;s &lt;a href=&#34;http://www.harding.edu/fmccown/R/&#34;&gt;Producing Simple Graphs with R&lt;/a&gt; tutorial. I have my own share of R related slides &lt;a href=&#34;http://www.biostat.jhsph.edu/~lcollado/teaching.html#.UDblsWie5Ng&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Learning Bioconductor. Thomas Girke again wrote a great resource for learning how to use &lt;a href=&#34;http://manuals.bioinformatics.ucr.edu/home/ht-seq#Introduction&#34;&gt;Bioconductor for analyzing high-throughput sequencing data files&lt;/a&gt;. Bioconductor hosts packages for other technologies/problems, so I would also look at it&amp;#8217;s own help pages like the Workflows section. I also like &lt;a href=&#34;http://www2.warwick.ac.uk/fac/sci/moac/people/students/peter_cock/r&#34;&gt;Peter&amp;#8217;s R programming pages&lt;/a&gt;, specially the heatmap section. I have my own share of Bioconductor related slides &lt;a href=&#34;http://www.biostat.jhsph.edu/~lcollado/teaching.html#.UDblsWie5Ng&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Learning LaTeX. I learnt the hard way I guess&amp;#8230; I learnt by comparing Sweave files and their output and seeing what changed if I modified the code. Nowadays, I would very highly recommend that you first check the &lt;a href=&#34;http://www.uwlax.edu/faculty/matchett/late/late.htm&#34;&gt;How to Use LaTeX&lt;/a&gt; short series of exercises/files by Andrew Matchett. The &lt;a href=&#34;http://tobi.oetiker.ch/lshort/lshort.pdf&#34;&gt;Not so short introduction to LaTeX&lt;/a&gt; is a great resource. For very specific symbols, check the &lt;a href=&#34;http://www.ung.si/~sstanic/teaching/CIS/LaTeX_symbols-a4.pdf&#34;&gt;Comprehensive LaTeX symbol list&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Using a SGE (Sun Grid Engine) cluster. For some basic commands look &lt;a href=&#34;http://www.rcc.uh.edu/hpc-docs/49-using-torque-to-submit-and-monitor-jobs.html&#34;&gt;here&lt;/a&gt;. For the Hopkins cluster, definitely read &lt;a href=&#34;http://www.biostat.jhsph.edu/bit/cluster-usage.html&#34;&gt;this&lt;/a&gt;. Finally, for running array jobs check &lt;a href=&#34;https://wiki.duke.edu/display/SCSC/SGE+Array+Jobs&#34;&gt;this&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;LaTeX and math. You should definitely &lt;a href=&#34;http://en.wikibooks.org/wiki/LaTeX/Mathematics&#34;&gt;read the wiki books page for this topic&lt;/a&gt;. I kept going back to it over my first year at Hopkins when I really needed to learn all this. The &lt;a href=&#34;http://en.wikibooks.org/wiki/LaTeX/Theorems&#34;&gt;theorems page&lt;/a&gt; is nice, but not a must. Same for &lt;a href=&#34;http://www.stat.ubc.ca/~webmaste/howto/editor/texerr.html&#34;&gt;Common TeX/LaTeX errors&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Figures in LaTeX. &lt;a href=&#34;http://www.hep.manchester.ac.uk/u/jenny/jcwdocs/latex/figures.html&#34;&gt;Here is a basic overview &lt;/a&gt;but the &lt;a href=&#34;http://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions&#34;&gt;wiki books page for the topic&lt;/a&gt; is a must check.&lt;/li&gt;
&lt;li&gt;Accents in LaTeX. Check this &lt;a href=&#34;http://fontignie.blogspot.com/2006/04/accents-in-latex.html&#34;&gt;blog post&lt;/a&gt; by &amp;#8220;Bugs and Solutions&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Blogging R code: &lt;a href=&#34;http://www.inside-r.org/pretty-r&#34;&gt;Pretty-R&lt;/a&gt;. I haven&amp;#8217;t really used it but it surely looks pretty!!&lt;/li&gt;
&lt;li&gt;Cloud storage: &lt;a href=&#34;https://www.dropbox.com/&#34;&gt;Dropbox&lt;/a&gt; works great and tons of iPad apps have an option to backup to it which works great with my note-taking apps. &lt;a href=&#34;https://drive.google.com/&#34;&gt;Google Drive&lt;/a&gt; and others are also around.&lt;/li&gt;
&lt;li&gt;Paper (biobliography) organizer: &lt;a href=&#34;http://www.zotero.org/&#34;&gt;Zotero&lt;/a&gt; is amazing! I simply love it :) I pull the bibliography from pubmed or the magazine page itself and to avoid any hassle, I have a &amp;#8220;papers&amp;#8221; folder in my Dropbox where I only organize them by last name. Then if I want to find something, I go to Zotero and look use it&amp;#8217;s great search function. I rarely use it to annotate webpages and I hear that it can now upload files to the cloud. Anyhow, I first used it in my Windows/Ubuntu dual setup. You can use it as a Zotero Firefox plugin or as Zotero stand-alone with Zotero Connector (Google Chrome for example). Finally, Zotero can export your bibliography into a BibTex file :)&lt;/li&gt;
&lt;li&gt;Blog: &lt;a href=&#34;http://www.tumblr.com/dashboard&#34;&gt;Tumblr&lt;/a&gt;. Some like WordPress better, but I like how Tumblr is not only a blogging platform but also a social media tool. I&amp;#8217;ve written &lt;a href=&#34;http://fellgernon.tumblr.com/tagged/Blog#.UDbiDGie5Ng&#34;&gt;several posts before on how to customize your blog&lt;/a&gt; and other blog related tools. But a must in my point of view is to get your RSS feed &amp;#8220;burnt&amp;#8221; with &lt;a href=&#34;http://feedburner.google.com&#34;&gt;feedburner&lt;/a&gt;. It has lots of interesting tools and is much better than a plain XML RSS feed.&lt;/li&gt;
&lt;li&gt;Notes: &lt;a href=&#34;http://itunes.apple.com/us/app/notability-take-notes-annotate/id360593530?mt=8&#34;&gt;Notability&lt;/a&gt; iPad app. Great stuff and doesn&amp;#8217;t blow up on you (aka, doesn&amp;#8217;t lose your notes) like &lt;a href=&#34;http://notesplusapp.com/&#34;&gt;NotesPlus&lt;/a&gt; did to me. Anyhow, note-taking in my iPad with auto-cloud backups greatly changed my classroom experience. THere are other apps like this one out there.&lt;/li&gt;
&lt;li&gt;I use &lt;a href=&#34;http://itunes.apple.com/us/app/voice-recorder-hd/id373045717?mt=8&#34;&gt;Voice Recorder HD&lt;/a&gt; iPad app for recording lectures. It&amp;#8217;s useful when you miss something the professor went over quickly and you are trying to understand it later on.&lt;/li&gt;
&lt;li&gt;Email: &lt;a href=&#34;http://www.gmail.com&#34;&gt;Gmail&lt;/a&gt; with keyboard shortcuts enabled. I also use &amp;#8220;Canned Responses&amp;#8221; from the Google Labs to specify my signature. I have an academic one, one for Mexico, etc.&lt;/li&gt;
&lt;li&gt;Send emails later: &lt;a href=&#34;http://www.boomeranggmail.com/&#34;&gt;Boomerang for Gmail&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Calendar: &lt;a href=&#34;https://www.google.com/calendar&#34;&gt;Google Calendar&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Task manager: Google Tasks from within Google Calendar (not from Gmail, which is doable too) with &lt;a href=&#34;http://itunes.apple.com/us/app/gotasks-google-tasks-client/id389113399?mt=8&#34;&gt;GoTasks&lt;/a&gt; in my iPhone.&lt;/li&gt;
&lt;li&gt;RSS reader: &lt;a href=&#34;http://www.google.com/reader/view/&#34;&gt;Google Reader&lt;/a&gt;. Works great. By the way, Orbvious interest (below) also works with Google Reader and has a customizable hotkey for it.&lt;/li&gt;
&lt;li&gt;Mark pages to read later: &lt;a href=&#34;http://shalom.craimer.org/projects/orbviousinterest/&#34;&gt;Orbvious Interest&lt;/a&gt; for Google Chrome. Great stuff! It syncs between computers and you can use Pocket in your iPad to view the links. &lt;/li&gt;
&lt;li&gt;Maps: &lt;a href=&#34;https://maps.google.com/&#34;&gt;Google Maps&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Video conversation: &lt;a&gt;Skype&lt;/a&gt;, Google Hangouts. If I&amp;#8217;m going to help someone remotely, then I use &lt;a href=&#34;http://www.teamviewer.com/en/index.aspx&#34;&gt;TeamViewer&lt;/a&gt; which is free for non-profit purposes. With it you can move their mouse, which makes things much easier for support issues!&lt;/li&gt;
&lt;li&gt;Photos: &lt;a href=&#34;http://picasa.google.com/&#34;&gt;Picasa&lt;/a&gt;. I pay the 5 bucks a year for 20&amp;#160;GB on Picasa Web Albums so all my photos are on the cloud.&lt;/li&gt;
&lt;li&gt;Dictionary: &lt;a href=&#34;http://dictionary.die.net/&#34;&gt;die.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Network visualizer/analyzer: &lt;a href=&#34;http://www.cytoscape.org/&#34;&gt;Cytoscape&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://bioinformatics.psb.ugent.be/webtools/Venn/&#34;&gt;Venn diagrams&lt;/a&gt; with more than 2 sets.&lt;/li&gt;
&lt;li&gt;Setting up your website. I pretty much followed Alyssa&amp;#8217;s instructions and got my CSS template for &lt;a href=&#34;http://www.biostat.jhsph.edu/~lcollado/#.UDbpKmie5Ng&#34;&gt;my academic page&lt;/a&gt; from &lt;a href=&#34;http://www.freecsstemplates.org/&#34;&gt;FCT&lt;/a&gt;. Then I used simple html to modify it.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I pretty much dumped a ton of my bookmarks in this huuuuge post! Well, I hope that it will be useful to someone. At least now I&amp;#8217;m happy to have contributed to Hilary&amp;#8217;s computing-resources-post drive.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The new visualization package for genome data in Bioconductor: ggbio</title>
      <link>http://lcolladotor.github.io/2011/12/06/the-new-visualization-package-for-genome-data-in</link>
      <pubDate>Tue, 06 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2011/12/06/the-new-visualization-package-for-genome-data-in</guid>
      <description>&lt;p&gt;It&amp;#8217;s been a while since I&amp;#8217;ve been waiting for the release of a visualization package in Bioconductor. Back in 2008 I was really impressed by the power of&lt;a href=&#34;http://www.bioconductor.org/packages/release/bioc/html/GenomeGraphs.html&#34;&gt; GenomeGraphs&lt;/a&gt; and I have used it in multiple occasions. Yet from both the &lt;a href=&#34;http://www-huber.embl.de/biocdeveleurope2010/&#34;&gt;Bioconductor Developer Meeting in Heidelberg 2010&lt;/a&gt; and &lt;a href=&#34;https://secure.bioconductor.org/BioC2011/&#34;&gt;BioC2011&lt;/a&gt; I&amp;#8217;ve been waiting for the release of the visualization tools developed by Michael Lawrence and Tengfei Yin at Genentech. &lt;/p&gt;
&lt;p&gt;So, after a long hiatus where I didn&amp;#8217;t browse the &lt;a href=&#34;http://www.bioconductor.org/packages/release/BiocViews.html&#34;&gt;biocviews&lt;/a&gt; in Bioconductor, I found out that Lawrence and Yin released &lt;a href=&#34;http://www.bioconductor.org/packages/release/bioc/html/ggbio.html&#34;&gt;ggbio&lt;/a&gt; and &lt;a href=&#34;http://www.bioconductor.org/packages/release/bioc/html/biovizBase.html&#34;&gt;biovizBase&lt;/a&gt; (it&amp;#8217;s more of an infrastructure package for ggbio) . I haven&amp;#8217;t really had the time to play around with them, but it&amp;#8217;s definitely worth exploring both of their vignette files: &lt;a href=&#34;http://www.bioconductor.org/packages/release/bioc/vignettes/ggbio/inst/doc/intro.pdf&#34;&gt;ggbio&lt;/a&gt;, &lt;a href=&#34;http://www.bioconductor.org/packages/release/bioc/vignettes/biovizBase/inst/doc/intro.pdf&#34;&gt;biovizBase&lt;/a&gt;. I also think that they&amp;#8217;ll fit very well in Bioconductor because quite a few of their examples involved the gamma of objects the BioC team has released for high-throughput sequencing (HTS) data. Meaning that they work well with objects from IRanges and GenomicRanges. Also, some of the examples use BAM files which are common nowadays in any HTS analysis pipeline. As a plus, ggbio uses&lt;a href=&#34;http://cran.r-project.org/web/packages/ggplot2/index.html&#34;&gt; ggplot2&lt;/a&gt;, which definitely makes clear nice plots.&lt;/p&gt;
&lt;p&gt;I expect ggbio to replace GenomeGraphs soon (although I love using it), but I&amp;#8217;m also kind of disappointed that I didn&amp;#8217;t see any of the cool examples from BioC2011 in ggbio&amp;#8217;s vignette file. After all, &lt;a href=&#34;https://github.com/tengfei/visnab&#34;&gt;visnab&lt;/a&gt; looked pretty impressive as &lt;a href=&#34;http://www.stat.iastate.edu/centers/CCGS/slides/slides-visnab.pdf&#34;&gt;you can see in this presentation&lt;/a&gt;. I don&amp;#8217;t know if they decided to rename visnab into ggbio, or maybe they haven&amp;#8217;t released visnab yet. Anyhow, give ggbio and biovizBase vignette files a look :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Biostatistics to first year LCG students</title>
      <link>http://lcolladotor.github.io/2011/12/04/introducing-biostatistics-to-first-year-lcg-students</link>
      <pubDate>Sun, 04 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>http://lcolladotor.github.io/2011/12/04/introducing-biostatistics-to-first-year-lcg-students</guid>
      <description>&lt;p&gt;Around two weeks ago I gave a talk via skype to the first year students from the &lt;a href=&#34;http://www.lcg.unam.mx/about&#34;&gt;Undergraduate Program on Genomic Sciences&lt;/a&gt; (LCG in Spanish) from the National Autonomous University of Mexico (UNAM in Spanish). The talk was under the context of the &lt;em&gt;Introduction to Bioinformatics Seminar Series&lt;/em&gt; whose goal is to familiarize the new students with the bioinformatics world. It used to be a course heavy on exploring database websites, some basic theory, and lots of new concepts and algorithm names. Like, what is BLAST? This year, the course involved several talks from former students (like myself) on their experience and current job (most of us are in graduate school).&lt;/p&gt;
&lt;p&gt;In my case, I was invited to talk about Biostatistics and R as I was one of the first LCG students to learn and teach R to other students (including PhD students ^^): &lt;a href=&#34;http://www.lcg.unam.mx/~lcollado/R/&#34;&gt;12 hour intro to R and Bioconductor&lt;/a&gt;, &lt;a href=&#34;http://www.lcg.unam.mx/~lcollado/E/&#34;&gt;R in an intro to statistics course&lt;/a&gt;, a &lt;a href=&#34;http://www.lcg.unam.mx/~lcollado/B/&#34;&gt;full course on Bioconductor&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;I had a lot of fun preparing my talk as I tried to portray the three main currents in Biostatistics in a way that would be understandable, basic concepts such as a P-value, some basic R code (the students knew the super basics only), and doing so in a way that I would also pass how I see things. A key part for any bioinformatician, as I see it, is to have a good basic toolset. That&amp;#8217;s why I tried to pass on many tips to these young students. Also, I do like to go back to the philosophy of science and whether we need hypothesis nowadays or just models based on the data. I definitely had to cover the topic of communication as I strongly believe that any researcher has to be able to communicate with a biostastician if they want their help in analyzing their data. Also, a biostatistician is not a stastistician, meaning that they have to understand the underlying biological question. I tried emphasizing this point with the students and I attempted to motivate them to take a basic stastistics and probability course (2 preferably). After all, biostatistics is key nowadays in science since biology has gone high-throughput.&lt;/p&gt;
&lt;p&gt;Giving the talk through skype was definitely a new experience for me. The best is to be in the classroom as you miss a lot of the interaction with the students. For instance, I didn&amp;#8217;t always know who as asking the question and frequently I had to ask them to repeat it louder. Plus, I chose to share my desktop with them instead of having them watch at my face all the time. I guess it wasn&amp;#8217;t easy for them to just watch a screen with a background voice for 2 hours :P But well, I hoped they liked it as much as I liked preparing it.&lt;/p&gt;
&lt;p&gt;If you are interested in the talk, I uploaded the &lt;a href=&#34;https://docs.google.com/open?id=0B-mxZfuflcuONmY1MGI3ZjEtN2JjNy00MDNiLTk0NmMtYjdiNDAwNTZmNGNj&#34;&gt;PDF file&lt;/a&gt;, the associated &lt;a href=&#34;https://docs.google.com/open?id=0B-mxZfuflcuOZTkxMDUzY2ItNmMzYi00ZDcyLTgyMTQtMWI5YzJmN2IzZjUw&#34;&gt;R file&lt;/a&gt; and the master &lt;a href=&#34;https://docs.google.com/open?id=0B-mxZfuflcuOYTY3OTQ4NjUtZTFkOC00MGQ5LThiMzgtNDQ2ZjY2NmZlY2Zi&#34;&gt;Rnw file&lt;/a&gt; to Google Docs. The Rnw file can be useful if you are learning how to write Beamer presentations using Sweave and LaTeX.&lt;/p&gt;

&lt;p&gt;&lt;p&gt;Finally, I was asked to prepare two short questions so that the teachers can evaluate the students. As a bonus for any of them reading my blog ^^ (I did portray blogs as an excellent way to update yourself) here they are:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Argue why you need to learn (at least basic) Biostatistics and why it&amp;#8217;s useful nowadays to analyze biological data.&lt;/li&gt;
&lt;li&gt;Based on the data from your recent experiment, you construct a 95% confidence interval (frequentist approach) for the mean of your variable of interest. What is the probability that the true mean of the distribution is contained in the confidence interval.&lt;/li&gt;
&lt;li&gt;Bonus: list 5 basic R plotting functions&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Answers:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;You need to learn the basics (at least) of Biostatistics in order to be able to communicate with your biostatistician collaborator, and to analyze your own data specially by performing exploratory data analyses (EDA). Also, biological experiments nowadays generate a lot of data as biology has gone high-throughput. Biostatistics is specially useful in order to analyze all this data.&lt;/li&gt;
&lt;li&gt;0 or 1 and you cannot know which is the case for your specific dataset.&lt;/li&gt;
&lt;li&gt;I mentioned: plot, hist, boxplot, qqplot, qqnorm, lines, points, abline, legend&lt;/li&gt;
&lt;/ol&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
